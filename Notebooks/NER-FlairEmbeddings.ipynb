{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('nlp-generic': conda)",
   "display_name": "Python 3.8.5 64-bit ('nlp-generic': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b481e22569f8c970d02674a5d9e45918cde1d33fcb13233e32a75967a14c2314"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Sentence: \"The grass is green .\"   [âˆ’ Tokens: 5]]"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "from flair.embeddings import FlairEmbeddings\n",
    "from flair.data import Sentence\n",
    "\n",
    "# init embedding\n",
    "flair_embedding_forward = FlairEmbeddings('news-forward-fast')\n",
    "\n",
    "# create a sentence\n",
    "sentence = Sentence('The grass is green .')\n",
    "\n",
    "# embed words in sentence\n",
    "flair_embedding_forward.embed(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Token: 1 The\ntensor([ 2.1388e-03, -1.0227e-06, -5.7348e-03,  ..., -1.6456e-09,\n        -7.8441e-05,  1.6318e-02], device='cuda:0')\ntorch.Size([1024])\n1024\nToken: 2 grass\ntensor([-8.7855e-04, -4.2676e-05,  2.4843e-02,  ..., -1.9470e-06,\n         6.3773e-04,  5.7139e-03], device='cuda:0')\ntorch.Size([1024])\n1024\nToken: 3 is\ntensor([ 1.8402e-03, -2.0841e-04,  2.9775e-02,  ..., -9.3616e-07,\n         1.6768e-05,  2.9047e-04], device='cuda:0')\ntorch.Size([1024])\n1024\nToken: 4 green\ntensor([-4.1963e-04, -1.5563e-05,  4.5961e-03,  ..., -4.5412e-08,\n        -1.1528e-04,  3.4503e-02], device='cuda:0')\ntorch.Size([1024])\n1024\nToken: 5 .\ntensor([ 8.2723e-04, -2.9691e-06,  4.9718e-03,  ..., -1.0784e-08,\n        -4.4279e-06,  2.0673e-03], device='cuda:0')\ntorch.Size([1024])\n1024\n"
     ]
    }
   ],
   "source": [
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding)\n",
    "    print(token.embedding.shape)\n",
    "    print(token.embedding.size()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence #</th>\n      <th>Word</th>\n      <th>POS</th>\n      <th>Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sentence: 1</td>\n      <td>Thousands</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>of</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>demonstrators</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>have</td>\n      <td>VBP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>marched</td>\n      <td>VBN</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "data = pd.read_csv('../Data/ner_dataset.csv',encoding='latin1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['POS'],inplace=True)\n",
    "data = data.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentence_getter():\n",
    "    def __init__(self,data):\n",
    "        agg_function = lambda s:[(w,t) for w,t in zip(s['Word'].values.tolist(),\n",
    "                                                      s['Tag'].values.tolist())]\n",
    "        self.grouped_data = data.groupby('Sentence #').apply(agg_function)\n",
    "        self.sentences = [s for s in self.grouped_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('Helicopter', 'O'),\n",
       " ('gunships', 'O'),\n",
       " ('Saturday', 'B-tim'),\n",
       " ('pounded', 'O'),\n",
       " ('militant', 'O'),\n",
       " ('hideouts', 'O'),\n",
       " ('in', 'O'),\n",
       " ('the', 'O'),\n",
       " ('Orakzai', 'B-geo'),\n",
       " ('tribal', 'O'),\n",
       " ('region', 'O'),\n",
       " (',', 'O'),\n",
       " ('where', 'O'),\n",
       " ('many', 'O'),\n",
       " ('Taliban', 'B-org'),\n",
       " ('militants', 'O'),\n",
       " ('are', 'O'),\n",
       " ('believed', 'O'),\n",
       " ('to', 'O'),\n",
       " ('have', 'O'),\n",
       " ('fled', 'O'),\n",
       " ('to', 'O'),\n",
       " ('avoid', 'O'),\n",
       " ('an', 'O'),\n",
       " ('earlier', 'O'),\n",
       " ('military', 'O'),\n",
       " ('offensive', 'O'),\n",
       " ('in', 'O'),\n",
       " ('nearby', 'O'),\n",
       " ('South', 'B-geo'),\n",
       " ('Waziristan', 'I-geo'),\n",
       " ('.', 'O')]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "getter = sentence_getter(data)\n",
    "sentences = getter.sentences\n",
    "sentences[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(data[\"Word\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "n_words = len(words)\n",
    "word_index = {w : i + 1 for i ,w in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = list(set(data[\"Tag\"].values))\n",
    "num_tags = len(tags)\n",
    "tag_index =  {t : i for i ,t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'I-per': 0,\n",
       " 'B-eve': 1,\n",
       " 'I-art': 2,\n",
       " 'B-org': 3,\n",
       " 'B-gpe': 4,\n",
       " 'O': 5,\n",
       " 'I-org': 6,\n",
       " 'B-art': 7,\n",
       " 'B-nat': 8,\n",
       " 'I-eve': 9,\n",
       " 'B-per': 10,\n",
       " 'B-tim': 11,\n",
       " 'I-tim': 12,\n",
       " 'I-geo': 13,\n",
       " 'B-geo': 14,\n",
       " 'I-nat': 15,\n",
       " 'I-gpe': 16}"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "tag_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[word_index[w[0]] for w in s] for s in sentences]\n",
    "X = tf.keras.preprocessing.sequence.pad_sequences(maxlen=50,sequences=X,padding='post', value = n_words - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sequences_padded = tf.keras.preprocessing.sequence.pad_sequences(X,\n",
    "maxlen=max_len,\n",
    "value = n_words - 1,\n",
    "padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = len(word_index)+1\n",
    "EMBEDDING_DIM = 1024\n",
    "\n",
    "embedding_matrix =np.zeros((vocabulary_size,EMBEDDING_DIM))\n",
    "\n",
    "for word,i in word_index.items():\n",
    "    try:\n",
    "        word_embedding = Sentence(word)\n",
    "        flair_embedding_forward.embed(word_embedding)\n",
    "        embedding_vector = word_embedding[0].embedding.cpu().detach().numpy()\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except KeyError:\n",
    "        embedding_matrix[i] = np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [[tag_index[w[1]] for w in s] for s in sentences]\n",
    "y = tf.keras.preprocessing.sequence.pad_sequences(maxlen=50,sequences=y,padding='post',value=tag_index['O'])\n",
    "y = [tf.keras.utils.to_categorical(i,num_classes=num_tags) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_sequences_padded,y,test_size = 0.1,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(vocabulary_size,EMBEDDING_DIM,weights = [embedding_matrix],trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # Embedding Layer \n",
    "    embedding_layer,\n",
    "    # Bidiretional LSTM for learning Long term dependencies\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim,return_sequences=True)),\n",
    "    # Dense Layer with RELU\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(embedding_dim,activation='relu')),\n",
    "    # Ouput layer with 16 units\n",
    "    tf.keras.layers.Dense(num_tags,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  }
 ]
}